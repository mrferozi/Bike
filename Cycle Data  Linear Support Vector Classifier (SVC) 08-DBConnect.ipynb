{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Declaration ***: The central idea and coding  is abstract  from Kevin mark ham youtube video seriese, Introduction to machine learning with scikit-learn video series. You can find link under resources section.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the **features**?\n",
    "- trip_id: A unique number to identify each trip\n",
    "\n",
    "- From station Number: From station number where the trip Start    \n",
    "    \n",
    "- Day: Day of the trip for example Monday, Tuesday etc.\n",
    "    \n",
    "- Month: Which month trip took place\n",
    "    \n",
    "- Duration: Total trip duration in minutes\n",
    "    \n",
    "- birthyear: Birth year of user\n",
    "    \n",
    "- Sex: Gender identification of user\n",
    "    \n",
    "- age: Current age of user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the **response**?\n",
    "- Station Number: To Station Number where the trip ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Could we predict the End station of a bicycle trip before journey start?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,csv,io,mapsplotlib,time,folium,googlemaps,geopy,zipfile,requests,warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import mysql.connector as sql\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display plots in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to obtain better accuracy with all end stations (to_station). With all end station the model predicts 0.067 percent of accuracy, to avoid this this study focus on a circumscribed number of end station. From our following query we are supposing here that ‘it does not matter where the bicycle trip will start. We are more interested in where this trip ends and to reach this goal. We havechoosen five main busiest end stations. Let’s say’s if a journey start from A, B and C station what is the chances it will end on the given end stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>from_station_id_num</th>\n",
       "      <th>to_station_id</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>to_station_id_num</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25845</th>\n",
       "      <td>254994</td>\n",
       "      <td>8.23</td>\n",
       "      <td>Dexter Ave N &amp; Aloha St</td>\n",
       "      <td>34</td>\n",
       "      <td>SLU-15</td>\n",
       "      <td>6th Ave</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25846</th>\n",
       "      <td>254998</td>\n",
       "      <td>9.15</td>\n",
       "      <td>E Thomas St</td>\n",
       "      <td>14</td>\n",
       "      <td>SLU-15</td>\n",
       "      <td>6th Ave</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25847</th>\n",
       "      <td>255058</td>\n",
       "      <td>7.89</td>\n",
       "      <td>E Pine St</td>\n",
       "      <td>16</td>\n",
       "      <td>SLU-15</td>\n",
       "      <td>6th Ave</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25848</th>\n",
       "      <td>255087</td>\n",
       "      <td>8.03</td>\n",
       "      <td>E Pine St</td>\n",
       "      <td>16</td>\n",
       "      <td>SLU-15</td>\n",
       "      <td>6th Ave</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25849</th>\n",
       "      <td>255149</td>\n",
       "      <td>5.97</td>\n",
       "      <td>Elliott Ave</td>\n",
       "      <td>1</td>\n",
       "      <td>SLU-15</td>\n",
       "      <td>6th Ave</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trip_id  Duration        from_station_name  from_station_id_num  \\\n",
       "25845   254994      8.23  Dexter Ave N & Aloha St                   34   \n",
       "25846   254998      9.15              E Thomas St                   14   \n",
       "25847   255058      7.89                E Pine St                   16   \n",
       "25848   255087      8.03                E Pine St                   16   \n",
       "25849   255149      5.97              Elliott Ave                    1   \n",
       "\n",
       "      to_station_id to_station_name  to_station_id_num  Day  Month  Year  age  \\\n",
       "25845        SLU-15         6th Ave                 38    6      8  2016   30   \n",
       "25846        SLU-15         6th Ave                 38    6      8  2016   42   \n",
       "25847        SLU-15         6th Ave                 38    6      8  2016   31   \n",
       "25848        SLU-15         6th Ave                 38    6      8  2016   46   \n",
       "25849        SLU-15         6th Ave                 38    6      8  2016   49   \n",
       "\n",
       "       Sex  Hours  \n",
       "25845    1      8  \n",
       "25846    1      8  \n",
       "25847    1     11  \n",
       "25848    1     13  \n",
       "25849    1     17  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data from database\n",
    "db_connection = sql.connect(host='localhost', database='bike', user='root', password='none')\n",
    "db_cursor = db_connection.cursor()\n",
    "db_cursor.execute('SELECT trip_id,tripduration_minutes Duration,from_station_name,from_station_id_num,to_station_id,to_station_name,to_station_id_num,Day_num Day,bmonth Month,year Year,age,Sex_num Sex,sthours Hours FROM bike.trip_clean where to_station_id_num in(7,9,36,37,38) order by to_station_id_num;')\n",
    "table_rows = db_cursor.fetchall()\n",
    "data = pd.read_sql('SELECT trip_id,tripduration_minutes Duration,from_station_name,from_station_id_num,to_station_id,to_station_name,to_station_id_num,Day_num Day,bmonth Month,year Year,age,Sex_num Sex,sthours Hours FROM bike.trip_clean where to_station_id_num in(7,9,36,37,38) order by to_station_id_num;', con=db_connection)\n",
    "df = pd.DataFrame(data)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['Duration','from_station_id_num','Hours','age','Sex']\n",
    "X = df[feature_cols]\n",
    "y = df.to_station_id_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(loss = 'l2') # instantiated with L2 loss\n",
    "print (clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating an instance of the classifier.  This can be done simply by calling the class name, with any arguments that the object accepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(loss = 'l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``clf`` is a statistical model that has parameters that control the learning algorithm (those parameters are sometimes called the *hyperparameters*). Those hyperparameters can be supplied by the user in the constructor of the model. We will discuss later how to choose a good combination using either simple empirical rules or data driven selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print (clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the model parameters are not initialized. They will be tuned automatically from the data by calling the ``fit`` method with the data ``X`` and labels ``y``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see some of the fit parameters within the classifier object.\n",
    "\n",
    "**In scikit-learn, parameters defined by training have a trailing underscore.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00950903, -0.01109086, -0.03497464,  0.00547468,  0.14144825],\n",
       "       [ 0.02200425, -0.00867309, -0.0049677 , -0.00078617, -0.037603  ],\n",
       "       [ 0.00770462, -0.01191933, -0.03452227, -0.01234906, -0.20865379],\n",
       "       [-0.01293034, -0.0135128 , -0.01560987,  0.01064128,  0.20328287],\n",
       "       [-0.01407   , -0.00418773, -0.00857613,  0.02144292, -0.05450888]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.62125724, -0.68454511,  0.35656843, -0.80650014, -1.15293788])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, it can be used to predict the most likely outcome on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37], dtype=int64)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here is the from station number. What end station does this get predicted as?\n",
    "X_new = [[22, 31, 35, 7, 9]] \n",
    "clf.predict(X_new) #end station number 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All classification tasks involve predicting an unknown category based on observed features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.26817904  0.11485692  0.0005781   0.56730664  0.0490793 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf2 = LogisticRegression()\n",
    "clf2.fit(X, y)\n",
    "print (clf2.predict_proba(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37], dtype=int64)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.predict(X_new) #end station number 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result gives the probability (between zero and one) that the test point comes from any of the three classes.\n",
    "\n",
    "This means that the model estimates that the sample in X_new has:\n",
    "\n",
    "- 90% likelyhood to belong to the ‘to station’ class (``end station = 37``)\n",
    "- 9% likelyhood to belong to the ‘to station’ class (``end station = 36``)\n",
    "- < 1% likelyhood to belong to the ‘to station’ class (``end station = 38``)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a rough evaluation our model by using\n",
    "it to predict the values of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model = clf2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "5        False\n",
      "6        False\n",
      "7        False\n",
      "8         True\n",
      "9        False\n",
      "10       False\n",
      "11       False\n",
      "12       False\n",
      "13       False\n",
      "14       False\n",
      "15        True\n",
      "16       False\n",
      "17        True\n",
      "18       False\n",
      "19       False\n",
      "20       False\n",
      "21       False\n",
      "22       False\n",
      "23       False\n",
      "24       False\n",
      "25       False\n",
      "26       False\n",
      "27       False\n",
      "28       False\n",
      "29       False\n",
      "         ...  \n",
      "25820    False\n",
      "25821    False\n",
      "25822    False\n",
      "25823    False\n",
      "25824    False\n",
      "25825    False\n",
      "25826    False\n",
      "25827    False\n",
      "25828    False\n",
      "25829    False\n",
      "25830    False\n",
      "25831    False\n",
      "25832    False\n",
      "25833    False\n",
      "25834    False\n",
      "25835    False\n",
      "25836    False\n",
      "25837    False\n",
      "25838    False\n",
      "25839    False\n",
      "25840     True\n",
      "25841     True\n",
      "25842    False\n",
      "25843    False\n",
      "25844    False\n",
      "25845    False\n",
      "25846    False\n",
      "25847    False\n",
      "25848     True\n",
      "25849    False\n",
      "Name: to_station_id_num, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print (y_model == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most of the predictions are incorrect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Classification Performance: Validation & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning the parameters of a prediction function and testing it on the\n",
    "same data is a methodological mistake: a model that would just repeat\n",
    "the labels of the samples that it has just seen would have a perfect\n",
    "score but would fail to predict anything useful on yet-unseen data.\n",
    "\n",
    "To avoid over-fitting, we have to define two different sets:\n",
    "\n",
    "- a training set X_train, y_train which is used for learning the parameters of a predictive model\n",
    "- a testing set X_test, y_test which is used for evaluating the fitted predictive model\n",
    "\n",
    "In scikit-learn such a random split can be quickly computed with the\n",
    "`train_test_split` helper function.  It can be used this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25850, 5) (19387, 5) (6463, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.25, random_state=0) # 25% of test data\n",
    "\n",
    "print (X.shape, X_train.shape, X_test.shape) #  Training data => (6463, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train on the training data, and test on the testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15014    False\n",
      "15095     True\n",
      "8653      True\n",
      "15333    False\n",
      "22750    False\n",
      "10281    False\n",
      "10227    False\n",
      "3861     False\n",
      "19032    False\n",
      "6662     False\n",
      "10139     True\n",
      "1799      True\n",
      "21841    False\n",
      "4043     False\n",
      "4725      True\n",
      "24434    False\n",
      "21407    False\n",
      "21838    False\n",
      "13339    False\n",
      "20510    False\n",
      "4285     False\n",
      "12461    False\n",
      "19098    False\n",
      "5619     False\n",
      "379      False\n",
      "21396    False\n",
      "5192     False\n",
      "3822     False\n",
      "15548    False\n",
      "25161    False\n",
      "         ...  \n",
      "25166    False\n",
      "5274      True\n",
      "20725    False\n",
      "11758    False\n",
      "25186    False\n",
      "14466    False\n",
      "24563    False\n",
      "13321    False\n",
      "20033    False\n",
      "20672    False\n",
      "1143      True\n",
      "23027    False\n",
      "6331      True\n",
      "25178    False\n",
      "16581    False\n",
      "19207    False\n",
      "15234    False\n",
      "13045    False\n",
      "6644      True\n",
      "16760    False\n",
      "23173    False\n",
      "7597      True\n",
      "16136     True\n",
      "17487    False\n",
      "878       True\n",
      "467      False\n",
      "7016     False\n",
      "5536     False\n",
      "15761    False\n",
      "5583     False\n",
      "Name: to_station_id_num, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(loss='l2').fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print (y_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an issue here, however:\n",
    "by defining these two sets, we drastically reduce the number\n",
    "of samples which can be used for learning the model, and the results\n",
    "can depend on a particular random choice for the pair of (train, test) sets.\n",
    "\n",
    "A solution is to split the whole data several consecutive times in different\n",
    "train set and test set, and to return the averaged value of the prediction\n",
    "scores obtained with the different sets. Such a procedure is called **cross-validation**.\n",
    "This approach can be computationally expensive, but does not waste too much data\n",
    "(as it is the case when fixing an arbitrary test set), which is a major advantage\n",
    "in problem such as inverse inference where the number of samples is very small.\n",
    "\n",
    "We'll explore cross-validation , but\n",
    "for more information on cross-validation in scikit-learn here:\n",
    "http://scikit-learn.org/dev/modules/cross_validation.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation for parameter tuning, model selection, and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.1646294291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "# use train/test split with different random_state values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)\n",
    "\n",
    "# check classification accuracy of KNN with K=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print ((metrics.accuracy_score(y_test, y_pred))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we created a bunch of train/test splits, calculated the testing accuracy for each, and averaged the results together and That's the essense of **cross-validation!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Of K-cross Validation\n",
    "\n",
    "1. Split the dataset into K **equal** partitions (or \"folds\").\n",
    "2. Use fold 1 as the **testing set** and the union of the other folds as the **training set**.\n",
    "3. Calculate **testing accuracy**.\n",
    "4. Repeat steps 2 and 3 K times, using a **different fold** as the testing set each time.\n",
    "5. Use the **average testing accuracy** as the estimate of out-of-sample accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Select the best tuning parameters (aka \"hyperparameters\") for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76352396  0.76334107  0.76836814  0.65390565  0.68201161  0.70085139\n",
      "  0.68846749  0.70123839  0.68537152  0.59349593]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0057513886\n"
     ]
    }
   ],
   "source": [
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "print ((scores.mean())*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77018611022881145, 0.71980910690268751, 0.70778630842517321, 0.70191100103433901, 0.70005751388561444, 0.69456571797540645, 0.68775720442010313, 0.68625010043589507, 0.68338717619918021, 0.67882406712522447, 0.67503423561828779, 0.67031535609937565, 0.66540247068146352, 0.66145728601652398, 0.65801557129775445, 0.65600341199435996, 0.65279269844244692, 0.65112880600595235, 0.65074210827620882, 0.64799576192400632, 0.6468742639994598, 0.64521028196917174, 0.64385661520741366, 0.641302869332942, 0.63863440041152075, 0.63697047844981969, 0.6358491001533868, 0.63352840515897724, 0.63105301602567088, 0.62938949864783933]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "k_range = range(1, 31)\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "print (k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1bcf1abe4e0>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEFCAYAAAAMk/uQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY4wxLf4/W182BKHYGhEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bcf0da5080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graphs display the lower value of k is better for our model accuracy and with K=1 we will get max of 76 percent of accuracy which is ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Compare the best KNN model with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.9809106903\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with the best KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "print ((cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.9206953717\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print ((cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result we are selecting KNN Neighbours with K=1 which is produce a better mean accuracy which is 72 percent aproximately. As compare to logistic regression. The logistic regression offer mean accuracy of 26.92 which is approximately 27 percent that is very low. So, because of that result, this study will use KNN Neighbours with k=1 for our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements to cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeated cross-validation**\n",
    "\n",
    "- Repeat cross-validation multiple times (with **different random splits** of the data) and average the results\n",
    "- More reliable estimate of out-of-sample performance by **reducing the variance** associated with a single trial of cross-validation\n",
    "\n",
    "**Creating a hold-out set**\n",
    "\n",
    "- \"Hold out\" a portion of the data **before** beginning the model building process\n",
    "- Locate the best model using cross-validation on the remaining data, and test it **using the hold-out set**\n",
    "- More reliable estimate of out-of-sample performance since hold-out set is **truly out-of-sample**\n",
    "\n",
    "**Feature engineering and selection within cross-validation iterations**\n",
    "\n",
    "- Normally, feature engineering and selection occurs **before** cross-validation\n",
    "- Instead, perform all feature engineering and selection **within each cross-validation iteration**\n",
    "- More reliable estimate of out-of-sample performance since it **better mimics** the application of the model to out-of-sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "References:*From the video series: [Introduction to machine learning with scikit-learn](https://github.com/justmarkham/scikit-learn-videos)*\n",
    "- scikit-learn documentation: [Cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html), [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- scikit-learn issue on GitHub: [MSE is negative when returned by cross_val_score](https://github.com/scikit-learn/scikit-learn/issues/2439)\n",
    "- Section 5.1 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) (11 pages) and related videos: [K-fold and leave-one-out cross-validation](https://www.youtube.com/watch?v=nZAM5OXrktY) (14 minutes), [Cross-validation the right and wrong ways](https://www.youtube.com/watch?v=S06JpVoNaA0) (10 minutes)\n",
    "- Scott Fortmann-Roe: [Accurately Measuring Model Prediction Error](http://scott.fortmann-roe.com/docs/MeasuringError.html)\n",
    "- Machine Learning Mastery: [An Introduction to Feature Selection](http://machinelearningmastery.com/an-introduction-to-feature-selection/)\n",
    "- Harvard CS109: [Cross-Validation: The Right and Wrong Way](https://github.com/cs109/content/blob/master/lec_10_cross_val.ipynb)\n",
    "- Journal of Cheminformatics: [Cross-validation pitfalls when selecting and assessing regression and classification models](http://www.jcheminf.com/content/pdf/1758-2946-6-10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
